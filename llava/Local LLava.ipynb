{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Download and convert the weights of LlaVA into MLX, and test the forward pass of this model on example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlx_path = Path('mlx_model')\n",
    "\n",
    "if not os.path.exists(mlx_path):\n",
    "    os.makedirs(mlx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [00:00<00:00, 207126.12it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "from convert import get_model_path, fetch_from_hub, hf_repo\n",
    "\n",
    "\n",
    "model_path = get_model_path(hf_repo)\n",
    "model_config, model_weights, model_weight_files, config, tokenizer = fetch_from_hub(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting\n",
      "[INFO] Saving\n"
     ]
    }
   ],
   "source": [
    "from utils import map_weights, should_keep_weight\n",
    "\n",
    "\n",
    "print(\"[INFO] Converting\")\n",
    "mlx_weights = dict(map_weights(k, v) for (k, v) in model_weights.items())\n",
    "mlx_weights = {k: v for (k, v) in mlx_weights.items() if should_keep_weight(k)}\n",
    "print(\"[INFO] Saving\")\n",
    "mx.savez(str(mlx_path / \"weights.npz\"), **mlx_weights)\n",
    "for fn in [\"config.json\", \"merges.txt\", \"vocab.json\", \"preprocessor_config.json\"]:\n",
    "    if fn in os.listdir(model_path):\n",
    "        shutil.copyfile(\n",
    "            str(model_path / f\"{fn}\"),\n",
    "            str(mlx_path / f\"{fn}\"),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llava import LlaVAConfig, LLMConfig, VisionConfig, ProjectionConfig, LlavaModel\n",
    "\n",
    "llava_mlx_config = LlaVAConfig(\n",
    "    llm_config=LLMConfig(\n",
    "        dim=4096,\n",
    "        n_layers=32,\n",
    "        head_dim=4096,\n",
    "        hidden_dim=11008,\n",
    "        norm_eps=1e-5,\n",
    "        n_heads=32, # TODO: should be 32 https://huggingface.co/lmsys/vicuna-7b-v1.5/blob/main/config.json#L14. But only works with 1. Please see llama file for how heads are split. Is this wrong?\n",
    "        n_kv_heads=32, # TODO: should be 32 https://huggingface.co/lmsys/vicuna-7b-v1.5/blob/main/config.json#L16\n",
    "        vocab_size=32064,\n",
    "        rope_theta=0,\n",
    "        rope_traditional=False\n",
    "    ),\n",
    "    vision_config=VisionConfig(\n",
    "        num_hidden_layers=24,\n",
    "        hidden_size=1024,\n",
    "        intermediate_size=4096,\n",
    "        num_attention_heads=16,\n",
    "        num_channels=3,\n",
    "        image_size=336,\n",
    "        patch_size=14\n",
    "    ),\n",
    "    projection_config=ProjectionConfig(\n",
    "        in_features=1024,\n",
    "        out_features=4096\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "model = LlavaModel(llava_mlx_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected shape (131072, 4096) but received  shape (4096, 4096) for parameter language_model.layers.0.attention.wq.weight",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlx_model/weights.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlx/lib/python3.10/site-packages/mlx/nn/layers/base.py:176\u001b[0m, in \u001b[0;36mModule.load_weights\u001b[0;34m(self, file_or_weights, strict)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected mx.array but received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v_new)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m             )\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v_new\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m v\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 176\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_new\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m             )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(tree_unflatten(weights))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected shape (131072, 4096) but received  shape (4096, 4096) for parameter language_model.layers.0.attention.wq.weight"
     ]
    }
   ],
   "source": [
    "model.load_weights('mlx_model/weights.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load images, and test generate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
